{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6539d336-793d-4c3a-9e8b-2be127f66d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e71b6e5-157e-4893-a68d-df196d988c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('csv/w2v_model2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0234bf7-0cf4-4c5a-a95f-977f53e1bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d52a09-5cc6-4512-a106-cf2aabd112ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_array = np.array([model.wv[word] for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a973defd-a6cf-4115-9777-4ba866afb9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โมเดลมีเวกเตอร์คำอยู่\n"
     ]
    }
   ],
   "source": [
    "if hasattr(model, 'wv') and len(model.wv) > 0:\n",
    "    print(\"โมเดลมีเวกเตอร์คำอยู่\")\n",
    "else:\n",
    "    print(\"โมเดลไม่มีเวกเตอร์คำ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59cf91d4-f5f5-4a2f-a03e-4b0c02ac638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(cleaned_text, model):\n",
    "    vectors = [model.wv[word] for word in cleaned_text if word in model.wv]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.nan  # กรณีไม่มีคำที่มีในโมเดล, คืนค่า NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e181fff3-8fdc-411b-93eb-d0f0f2b97985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences with vectors: 0\n"
     ]
    }
   ],
   "source": [
    "# คุณสามารถใช้วิธีนี้เพื่อนับจำนวนข้อความที่สามารถแปลงเป็นเวกเตอร์ได้:\n",
    "vec = cleaned_text.apply(lambda x: get_sentence_vector(x, model))\n",
    "\n",
    "# ตรวจสอบจำนวนข้อความที่สามารถแปลงเป็นเวกเตอร์ได้ (ไม่ใช่ NaN)\n",
    "num_vectors = vec.dropna().shape[0]\n",
    "print(f\"Number of sentences with vectors: {num_vectors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ce4a71-1e5d-47e5-a65a-2cc96323c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)  # Reduce to 2 dimensions\n",
    "reduced_vecs = pca.fit_transform(vec_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4a0486d-8c63-4eb4-a50c-453ac92de3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_sentence_vector(cleaned_text, model)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3c76a60-e48a-4a42-bb0b-3c1c6bbbb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/home/jovyan/work/code/csv/class.csv',encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae7d254-44b7-4e83-b78f-d69a7ed6217c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ทักษิณ ขยับ เรือนจำ ผวา สื่อ สำนัก พาดหัวข่าว ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>พล ตอ เสรี พิศุทธ์ ฟันธง บิ๊ก โจ๊ก ชนะ ปม ออกจ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ได้ยิน ข่าว ช่อง ว้าย ทีวี ทายาท มหาเศรษฐี นัก...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>คนเหนือ บอ คน ดี เหยียบ เมือง ร้อน แล้ง ข้าวยา...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ไทย รัฐบาล ค่า ไฟ ค่า น้ำมัน ค่า สลด ตอแหล ตอแ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>ประกาศ เลิกจ้าง พนักงาน คน ลอยแพ เจ้าของ โรงงา...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>ตรี นุช เปิดตัว แอปพลิเคชั่น ช่าง อาชีวะ ทีม ช...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>ฉีดวัคซีน ต้าน โควิด เด็กนักเรียน อายุ ปี เริ่...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>ตค ผู้สื่อข่าว รายงาน วันที่ ตุลาคม โรงเรียน อ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>ศูนย์บริการสาธารณสุข ลุย ตรวจ เชิงรุก หา เชื้อ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     ทักษิณ ขยับ เรือนจำ ผวา สื่อ สำนัก พาดหัวข่าว ...\n",
       "1     พล ตอ เสรี พิศุทธ์ ฟันธง บิ๊ก โจ๊ก ชนะ ปม ออกจ...\n",
       "2     ได้ยิน ข่าว ช่อง ว้าย ทีวี ทายาท มหาเศรษฐี นัก...\n",
       "3     คนเหนือ บอ คน ดี เหยียบ เมือง ร้อน แล้ง ข้าวยา...\n",
       "4     ไทย รัฐบาล ค่า ไฟ ค่า น้ำมัน ค่า สลด ตอแหล ตอแ...\n",
       "...                                                 ...\n",
       "6995  ประกาศ เลิกจ้าง พนักงาน คน ลอยแพ เจ้าของ โรงงา...\n",
       "6996  ตรี นุช เปิดตัว แอปพลิเคชั่น ช่าง อาชีวะ ทีม ช...\n",
       "6997  ฉีดวัคซีน ต้าน โควิด เด็กนักเรียน อายุ ปี เริ่...\n",
       "6998  ตค ผู้สื่อข่าว รายงาน วันที่ ตุลาคม โรงเรียน อ...\n",
       "6999  ศูนย์บริการสาธารณสุข ลุย ตรวจ เชิงรุก หา เชื้อ...\n",
       "\n",
       "[7000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = pd.read_csv('/home/jovyan/work/code/csv/cleaned_data.csv',encoding='utf-8')\n",
    "cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ea4a74-f907-4446-8046-145abdd6550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes are inconsistent.\n"
     ]
    }
   ],
   "source": [
    "if len(reduced_vecs) == len(labels):\n",
    "    print(\"Sizes are consistent.\")\n",
    "else:\n",
    "    print(\"Sizes are inconsistent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e100ed7-bc94-425b-8c5e-1e3b7fd568e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [31193, 7000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduced_vecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2777\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2781\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2782\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [31193, 7000]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reduced_vecs, labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6c548-b05c-479a-8536-b3aa56f69eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
